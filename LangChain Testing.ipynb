{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "collapsed": true,
        "id": "Yciznnjz5bmi",
        "outputId": "256215e0-d74c-47a9-e4f3-87a886dccadf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting langchain-community\n",
            "  Downloading langchain_community-0.3.1-py3-none-any.whl.metadata (2.8 kB)\n",
            "Collecting langgraph\n",
            "  Downloading langgraph-0.2.34-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting langchain-anthropic\n",
            "  Downloading langchain_anthropic-0.2.3-py3-none-any.whl.metadata (2.3 kB)\n",
            "Collecting tavily-python\n",
            "  Downloading tavily_python-0.5.0-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting langgraph-checkpoint-sqlite\n",
            "  Downloading langgraph_checkpoint_sqlite-2.0.0-py3-none-any.whl.metadata (3.0 kB)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (6.0.2)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (2.0.35)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (3.10.8)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain-community)\n",
            "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
            "Collecting langchain<0.4.0,>=0.3.1 (from langchain-community)\n",
            "  Downloading langchain-0.3.2-py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting langchain-core<0.4.0,>=0.3.6 (from langchain-community)\n",
            "  Downloading langchain_core-0.3.9-py3-none-any.whl.metadata (6.3 kB)\n",
            "Collecting langsmith<0.2.0,>=0.1.125 (from langchain-community)\n",
            "  Downloading langsmith-0.1.131-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (1.26.4)\n",
            "Collecting pydantic-settings<3.0.0,>=2.4.0 (from langchain-community)\n",
            "  Downloading pydantic_settings-2.5.2-py3-none-any.whl.metadata (3.5 kB)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (2.32.3)\n",
            "Collecting tenacity!=8.4.0,<9.0.0,>=8.1.0 (from langchain-community)\n",
            "  Downloading tenacity-8.5.0-py3-none-any.whl.metadata (1.2 kB)\n",
            "Collecting langgraph-checkpoint<3.0.0,>=2.0.0 (from langgraph)\n",
            "  Downloading langgraph_checkpoint-2.0.0-py3-none-any.whl.metadata (4.6 kB)\n",
            "Collecting anthropic<1,>=0.30.0 (from langchain-anthropic)\n",
            "  Downloading anthropic-0.35.0-py3-none-any.whl.metadata (18 kB)\n",
            "Requirement already satisfied: defusedxml<0.8.0,>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from langchain-anthropic) (0.7.1)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.10/dist-packages (from langchain-anthropic) (2.9.2)\n",
            "Collecting tiktoken>=0.5.1 (from tavily-python)\n",
            "  Downloading tiktoken-0.8.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
            "Collecting httpx (from tavily-python)\n",
            "  Downloading httpx-0.27.2-py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting aiosqlite<0.21.0,>=0.20.0 (from langgraph-checkpoint-sqlite)\n",
            "  Downloading aiosqlite-0.20.0-py3-none-any.whl.metadata (4.3 kB)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.4.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.1.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.13.1)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (4.0.3)\n",
            "Requirement already satisfied: typing_extensions>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiosqlite<0.21.0,>=0.20.0->langgraph-checkpoint-sqlite) (4.12.2)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from anthropic<1,>=0.30.0->langchain-anthropic) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from anthropic<1,>=0.30.0->langchain-anthropic) (1.7.0)\n",
            "Collecting jiter<1,>=0.4.0 (from anthropic<1,>=0.30.0->langchain-anthropic)\n",
            "  Downloading jiter-0.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.6 kB)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from anthropic<1,>=0.30.0->langchain-anthropic) (1.3.1)\n",
            "Requirement already satisfied: tokenizers>=0.13.0 in /usr/local/lib/python3.10/dist-packages (from anthropic<1,>=0.30.0->langchain-anthropic) (0.19.1)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
            "  Downloading marshmallow-3.22.0-py3-none-any.whl.metadata (7.2 kB)\n",
            "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx->tavily-python) (2024.8.30)\n",
            "Collecting httpcore==1.* (from httpx->tavily-python)\n",
            "  Downloading httpcore-1.0.6-py3-none-any.whl.metadata (21 kB)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx->tavily-python) (3.10)\n",
            "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx->tavily-python)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\n",
            "Collecting langchain-text-splitters<0.4.0,>=0.3.0 (from langchain<0.4.0,>=0.3.1->langchain-community)\n",
            "  Downloading langchain_text_splitters-0.3.0-py3-none-any.whl.metadata (2.3 kB)\n",
            "Collecting jsonpatch<2.0,>=1.33 (from langchain-core<0.4.0,>=0.3.6->langchain-community)\n",
            "  Downloading jsonpatch-1.33-py2.py3-none-any.whl.metadata (3.0 kB)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.6->langchain-community) (24.1)\n",
            "Collecting msgpack<2.0.0,>=1.1.0 (from langgraph-checkpoint<3.0.0,>=2.0.0->langgraph)\n",
            "  Downloading msgpack-1.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (8.4 kB)\n",
            "Collecting orjson<4.0.0,>=3.9.14 (from langsmith<0.2.0,>=0.1.125->langchain-community)\n",
            "  Downloading orjson-3.10.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (50 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m50.4/50.4 kB\u001b[0m \u001b[31m929.9 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting requests-toolbelt<2.0.0,>=1.0.0 (from langsmith<0.2.0,>=0.1.125->langchain-community)\n",
            "  Downloading requests_toolbelt-1.0.0-py2.py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain-anthropic) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain-anthropic) (2.23.4)\n",
            "Collecting python-dotenv>=0.21.0 (from pydantic-settings<3.0.0,>=2.4.0->langchain-community)\n",
            "  Downloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-community) (3.3.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-community) (2.2.3)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain-community) (3.1.1)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken>=0.5.1->tavily-python) (2024.9.11)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->anthropic<1,>=0.30.0->langchain-anthropic) (1.2.2)\n",
            "Collecting jsonpointer>=1.9 (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.6->langchain-community)\n",
            "  Downloading jsonpointer-3.0.0-py2.py3-none-any.whl.metadata (2.3 kB)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from tokenizers>=0.13.0->anthropic<1,>=0.30.0->langchain-anthropic) (0.24.7)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.0->anthropic<1,>=0.30.0->langchain-anthropic) (3.16.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.0->anthropic<1,>=0.30.0->langchain-anthropic) (2024.6.1)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.0->anthropic<1,>=0.30.0->langchain-anthropic) (4.66.5)\n",
            "Downloading langchain_community-0.3.1-py3-none-any.whl (2.4 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m24.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langgraph-0.2.34-py3-none-any.whl (107 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m107.4/107.4 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_anthropic-0.2.3-py3-none-any.whl (21 kB)\n",
            "Downloading tavily_python-0.5.0-py3-none-any.whl (14 kB)\n",
            "Downloading langgraph_checkpoint_sqlite-2.0.0-py3-none-any.whl (12 kB)\n",
            "Downloading aiosqlite-0.20.0-py3-none-any.whl (15 kB)\n",
            "Downloading anthropic-0.35.0-py3-none-any.whl (894 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m894.0/894.0 kB\u001b[0m \u001b[31m17.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Downloading httpx-0.27.2-py3-none-any.whl (76 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m76.4/76.4 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpcore-1.0.6-py3-none-any.whl (78 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m78.0/78.0 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain-0.3.2-py3-none-any.whl (1.0 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m33.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_core-0.3.9-py3-none-any.whl (401 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m401.8/401.8 kB\u001b[0m \u001b[31m17.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langgraph_checkpoint-2.0.0-py3-none-any.whl (22 kB)\n",
            "Downloading langsmith-0.1.131-py3-none-any.whl (294 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m294.6/294.6 kB\u001b[0m \u001b[31m14.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydantic_settings-2.5.2-py3-none-any.whl (26 kB)\n",
            "Downloading tenacity-8.5.0-py3-none-any.whl (28 kB)\n",
            "Downloading tiktoken-0.8.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m37.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jiter-0.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (318 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m318.9/318.9 kB\u001b[0m \u001b[31m18.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
            "Downloading langchain_text_splitters-0.3.0-py3-none-any.whl (25 kB)\n",
            "Downloading marshmallow-3.22.0-py3-none-any.whl (49 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m49.3/49.3 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading msgpack-1.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (378 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m378.0/378.0 kB\u001b[0m \u001b[31m21.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading orjson-3.10.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (141 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m141.9/141.9 kB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
            "Downloading requests_toolbelt-1.0.0-py2.py3-none-any.whl (54 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m54.5/54.5 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jsonpointer-3.0.0-py2.py3-none-any.whl (7.6 kB)\n",
            "Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Installing collected packages: tenacity, python-dotenv, orjson, mypy-extensions, msgpack, marshmallow, jsonpointer, jiter, h11, aiosqlite, typing-inspect, tiktoken, requests-toolbelt, jsonpatch, httpcore, pydantic-settings, httpx, dataclasses-json, tavily-python, langsmith, anthropic, langchain-core, langgraph-checkpoint, langchain-text-splitters, langchain-anthropic, langgraph-checkpoint-sqlite, langgraph, langchain, langchain-community\n",
            "  Attempting uninstall: tenacity\n",
            "    Found existing installation: tenacity 9.0.0\n",
            "    Uninstalling tenacity-9.0.0:\n",
            "      Successfully uninstalled tenacity-9.0.0\n",
            "  Attempting uninstall: msgpack\n",
            "    Found existing installation: msgpack 1.0.8\n",
            "    Uninstalling msgpack-1.0.8:\n",
            "      Successfully uninstalled msgpack-1.0.8\n",
            "Successfully installed aiosqlite-0.20.0 anthropic-0.35.0 dataclasses-json-0.6.7 h11-0.14.0 httpcore-1.0.6 httpx-0.27.2 jiter-0.5.0 jsonpatch-1.33 jsonpointer-3.0.0 langchain-0.3.2 langchain-anthropic-0.2.3 langchain-community-0.3.1 langchain-core-0.3.9 langchain-text-splitters-0.3.0 langgraph-0.2.34 langgraph-checkpoint-2.0.0 langgraph-checkpoint-sqlite-2.0.0 langsmith-0.1.131 marshmallow-3.22.0 msgpack-1.1.0 mypy-extensions-1.0.0 orjson-3.10.7 pydantic-settings-2.5.2 python-dotenv-1.0.1 requests-toolbelt-1.0.0 tavily-python-0.5.0 tenacity-8.5.0 tiktoken-0.8.0 typing-inspect-0.9.0\n"
          ]
        }
      ],
      "source": [
        "%pip install -U langchain-community langgraph langchain-anthropic tavily-python langgraph-checkpoint-sqlite"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "collapsed": true,
        "id": "Bgg-gzh55nAE",
        "outputId": "19398c12-d9cf-4dd2-d29a-6a21ef1b8c09"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·\n"
          ]
        }
      ],
      "source": [
        "import getpass\n",
        "import os\n",
        "\n",
        "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
        "os.environ[\"LANGCHAIN_API_KEY\"] = getpass.getpass()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "collapsed": true,
        "id": "xUaueYZ_7YXo",
        "outputId": "b697fbb1-e6bd-444e-8239-64b799462a85"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·\n"
          ]
        }
      ],
      "source": [
        "os.environ[\"TAVILY_API_KEY\"] = getpass.getpass()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "b8N1_e1U7j8-",
        "outputId": "7f7cc120-7eb4-492c-f3bd-26ed2c0a9e43"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[{'url': 'https://www.weatherapi.com/', 'content': \"{'location': {'name': 'Mississauga', 'region': 'Ontario', 'country': 'Canada', 'lat': 43.15, 'lon': -79.5, 'tz_id': 'America/Toronto', 'localtime_epoch': 1728164356, 'localtime': '2024-10-05 17:39'}, 'current': {'last_updated_epoch': 1728163800, 'last_updated': '2024-10-05 17:30', 'temp_c': 17.1, 'temp_f': 62.8, 'is_day': 1, 'condition': {'text': 'Sunny', 'icon': '//cdn.weatherapi.com/weather/64x64/day/113.png', 'code': 1000}, 'wind_mph': 5.6, 'wind_kph': 9.0, 'wind_degree': 87, 'wind_dir': 'E', 'pressure_mb': 1024.0, 'pressure_in': 30.23, 'precip_mm': 0.0, 'precip_in': 0.0, 'humidity': 46, 'cloud': 0, 'feelslike_c': 17.1, 'feelslike_f': 62.8, 'windchill_c': 18.5, 'windchill_f': 65.4, 'heatindex_c': 18.6, 'heatindex_f': 65.4, 'dewpoint_c': 9.3, 'dewpoint_f': 48.7, 'vis_km': 10.0, 'vis_miles': 6.0, 'uv': 5.0, 'gust_mph': 7.8, 'gust_kph': 12.5}}\"}, {'url': 'https://world-weather.info/forecast/canada/mississauga/may-2024/', 'content': 'Extended weather forecast in Mississauga. Hourly Week 10 days 14 days 30 days Year. Detailed âš¡ Mississauga Weather Forecast for May 2024 - day/night ğŸŒ¡ï¸ temperatures, precipitations - World-Weather.info.'}]\n"
          ]
        }
      ],
      "source": [
        "from langchain_community.tools.tavily_search import TavilySearchResults\n",
        "\n",
        "search = TavilySearchResults(max_results=2)\n",
        "search_results = search.invoke(\"What is the weather in Mississauga?\")\n",
        "print(search_results)\n",
        "# If we want, we can create other tools.\n",
        "# Once we have all the tools we want, we can put them in a list that we will reference later.\n",
        "tools = [search]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "collapsed": true,
        "id": "DPl4Q6rxoE0Q",
        "outputId": "8f269d51-07aa-425f-e247-56fa91daa225"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[?25l   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m0.0/49.7 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m49.7/49.7 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m0.0/383.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m383.5/383.5 kB\u001b[0m \u001b[31m14.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "%pip install -qU langchain-openai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "collapsed": true,
        "id": "jYNgoYQAoKIL",
        "outputId": "7ea3d9f1-4c58-4ca7-a538-cb24f8f24c5b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·\n"
          ]
        }
      ],
      "source": [
        "import getpass\n",
        "import os\n",
        "\n",
        "os.environ[\"OPENAI_API_KEY\"] = getpass.getpass()\n",
        "\n",
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "model = ChatOpenAI(model=\"gpt-4\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "RmDcP8JpoS-g",
        "outputId": "4e487b67-f130-4951-ec09-8a3dd7904f38"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Hello! How can I assist you today?'"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from langchain_core.messages import HumanMessage\n",
        "\n",
        "response = model.invoke([HumanMessage(content=\"hi!\")])\n",
        "response.content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "ovHvQa3MpIh9"
      },
      "outputs": [],
      "source": [
        "model_with_tools = model.bind_tools(tools)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "3O6YVE99pLSH",
        "outputId": "f36d457f-d49e-4588-9993-67b0657670a2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ContentString: Hello! How can I assist you today?\n",
            "ToolCalls: []\n"
          ]
        }
      ],
      "source": [
        "response = model_with_tools.invoke([HumanMessage(content=\"Hi!\")])\n",
        "\n",
        "print(f\"ContentString: {response.content}\")\n",
        "print(f\"ToolCalls: {response.tool_calls}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "Q1yBfCqOpQnH",
        "outputId": "70d5f500-f947-44a1-ad65-1fb2e6bd7f49"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ContentString: I'm sorry for the misunderstanding, but as a text-based AI model, I don't have the capability to provide real-time weather updates. I recommend checking a reliable weather forecast website or app for the most accurate information.\n",
            "ToolCalls: []\n"
          ]
        }
      ],
      "source": [
        "response = model_with_tools.invoke([HumanMessage(content=\"What's the weather in SF?\")])\n",
        "\n",
        "print(f\"ContentString: {response.content}\")\n",
        "print(f\"ToolCalls: {response.tool_calls}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "QHL9LzJKpxZb"
      },
      "outputs": [],
      "source": [
        "from langgraph.prebuilt import create_react_agent\n",
        "\n",
        "agent_executor = create_react_agent(model, tools)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "VuwbvkF_p35N",
        "outputId": "e75b8e46-f103-4d71-a2ca-338d5192681c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[HumanMessage(content='hi!', additional_kwargs={}, response_metadata={}, id='0a4521a3-141e-4a54-be18-1064bc8964a4'),\n",
              " AIMessage(content='Hello! How can I assist you today?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 10, 'prompt_tokens': 83, 'total_tokens': 93, 'completion_tokens_details': {'audio_tokens': None, 'reasoning_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': None, 'cached_tokens': 0}}, 'model_name': 'gpt-4-0613', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-054b6e3e-e6e4-4967-8f67-bcc0c9aa9088-0', usage_metadata={'input_tokens': 83, 'output_tokens': 10, 'total_tokens': 93, 'input_token_details': {'cache_read': 0}, 'output_token_details': {'reasoning': 0}})]"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "response = agent_executor.invoke({\"messages\": [HumanMessage(content=\"hi!\")]})\n",
        "\n",
        "response[\"messages\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "iXuYtUUTp7pr",
        "outputId": "29aa4055-9efa-4b56-a126-c39384e08800"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[HumanMessage(content='whats the weather in sf?', additional_kwargs={}, response_metadata={}, id='691c38de-2910-40d5-94dc-aa687c351389'),\n",
              " AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_zmJLNSz7L7xWcu4OTuZ3kZQa', 'function': {'arguments': '{\\n  \"query\": \"current weather in San Francisco\"\\n}', 'name': 'tavily_search_results_json'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 23, 'prompt_tokens': 88, 'total_tokens': 111, 'completion_tokens_details': {'audio_tokens': None, 'reasoning_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': None, 'cached_tokens': 0}}, 'model_name': 'gpt-4-0613', 'system_fingerprint': None, 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-ffd50695-5a27-453b-b350-3c8b29077fdb-0', tool_calls=[{'name': 'tavily_search_results_json', 'args': {'query': 'current weather in San Francisco'}, 'id': 'call_zmJLNSz7L7xWcu4OTuZ3kZQa', 'type': 'tool_call'}], usage_metadata={'input_tokens': 88, 'output_tokens': 23, 'total_tokens': 111, 'input_token_details': {'cache_read': 0}, 'output_token_details': {'reasoning': 0}}),\n",
              " ToolMessage(content='[{\"url\": \"https://www.weatherapi.com/\", \"content\": \"{\\'location\\': {\\'name\\': \\'San Francisco\\', \\'region\\': \\'California\\', \\'country\\': \\'United States of America\\', \\'lat\\': 37.775, \\'lon\\': -122.4183, \\'tz_id\\': \\'America/Los_Angeles\\', \\'localtime_epoch\\': 1728164819, \\'localtime\\': \\'2024-10-05 14:46\\'}, \\'current\\': {\\'last_updated_epoch\\': 1728164700, \\'last_updated\\': \\'2024-10-05 14:45\\', \\'temp_c\\': 27.8, \\'temp_f\\': 82.0, \\'is_day\\': 1, \\'condition\\': {\\'text\\': \\'Partly cloudy\\', \\'icon\\': \\'//cdn.weatherapi.com/weather/64x64/day/116.png\\', \\'code\\': 1003}, \\'wind_mph\\': 6.0, \\'wind_kph\\': 9.7, \\'wind_degree\\': 321, \\'wind_dir\\': \\'NW\\', \\'pressure_mb\\': 1014.0, \\'pressure_in\\': 29.95, \\'precip_mm\\': 0.0, \\'precip_in\\': 0.0, \\'humidity\\': 40, \\'cloud\\': 50, \\'feelslike_c\\': 27.5, \\'feelslike_f\\': 81.4, \\'windchill_c\\': 28.0, \\'windchill_f\\': 82.4, \\'heatindex_c\\': 27.9, \\'heatindex_f\\': 82.2, \\'dewpoint_c\\': 13.0, \\'dewpoint_f\\': 55.4, \\'vis_km\\': 16.0, \\'vis_miles\\': 9.0, \\'uv\\': 7.0, \\'gust_mph\\': 12.7, \\'gust_kph\\': 20.4}}\"}, {\"url\": \"https://forecast.weather.gov/MapClick.php?lat=37.777120000000025&lon=-122.41965999999996\", \"content\": \"Current conditions at SAN FRANCISCO DOWNTOWN (SFOC1) Lat: 37.77056Â°NLon: 122.42694Â°WElev: 150.0ft. NA. 58Â°F. 14Â°C. ... 2024-6pm PDT Oct 10, 2024 . Forecast Discussion . Additional Resources. Radar & Satellite Image. ... National Weather Service; San Francisco Bay Area, CA; 21 Grace Hopper Ave, Stop 5; Monterey, CA 93943-5505; Comments ...\"}]', name='tavily_search_results_json', id='81d34d08-d95b-4398-a4d4-68063653ea92', tool_call_id='call_zmJLNSz7L7xWcu4OTuZ3kZQa', artifact={'query': 'current weather in San Francisco', 'follow_up_questions': None, 'answer': None, 'images': [], 'results': [{'title': 'Weather in San Francisco', 'url': 'https://www.weatherapi.com/', 'content': \"{'location': {'name': 'San Francisco', 'region': 'California', 'country': 'United States of America', 'lat': 37.775, 'lon': -122.4183, 'tz_id': 'America/Los_Angeles', 'localtime_epoch': 1728164819, 'localtime': '2024-10-05 14:46'}, 'current': {'last_updated_epoch': 1728164700, 'last_updated': '2024-10-05 14:45', 'temp_c': 27.8, 'temp_f': 82.0, 'is_day': 1, 'condition': {'text': 'Partly cloudy', 'icon': '//cdn.weatherapi.com/weather/64x64/day/116.png', 'code': 1003}, 'wind_mph': 6.0, 'wind_kph': 9.7, 'wind_degree': 321, 'wind_dir': 'NW', 'pressure_mb': 1014.0, 'pressure_in': 29.95, 'precip_mm': 0.0, 'precip_in': 0.0, 'humidity': 40, 'cloud': 50, 'feelslike_c': 27.5, 'feelslike_f': 81.4, 'windchill_c': 28.0, 'windchill_f': 82.4, 'heatindex_c': 27.9, 'heatindex_f': 82.2, 'dewpoint_c': 13.0, 'dewpoint_f': 55.4, 'vis_km': 16.0, 'vis_miles': 9.0, 'uv': 7.0, 'gust_mph': 12.7, 'gust_kph': 20.4}}\", 'score': 0.9992139, 'raw_content': None}, {'title': 'National Weather Service', 'url': 'https://forecast.weather.gov/MapClick.php?lat=37.777120000000025&lon=-122.41965999999996', 'content': 'Current conditions at SAN FRANCISCO DOWNTOWN (SFOC1) Lat: 37.77056Â°NLon: 122.42694Â°WElev: 150.0ft. NA. 58Â°F. 14Â°C. ... 2024-6pm PDT Oct 10, 2024 . Forecast Discussion . Additional Resources. Radar & Satellite Image. ... National Weather Service; San Francisco Bay Area, CA; 21 Grace Hopper Ave, Stop 5; Monterey, CA 93943-5505; Comments ...', 'score': 0.99603915, 'raw_content': None}], 'response_time': 2.64}),\n",
              " AIMessage(content='The current weather in San Francisco, California is partly cloudy with a temperature of 27.8Â°C (82.0Â°F). The wind is coming from the northwest at a speed of 6.0 mph. The humidity is at 40% and visibility is 16.0 km. [Source](https://www.weatherapi.com/)', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 70, 'prompt_tokens': 684, 'total_tokens': 754, 'completion_tokens_details': {'audio_tokens': None, 'reasoning_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': None, 'cached_tokens': 0}}, 'model_name': 'gpt-4-0613', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-522efac2-d88d-4e3c-8257-be1232183d30-0', usage_metadata={'input_tokens': 684, 'output_tokens': 70, 'total_tokens': 754, 'input_token_details': {'cache_read': 0}, 'output_token_details': {'reasoning': 0}})]"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "response = agent_executor.invoke(\n",
        "    {\"messages\": [HumanMessage(content=\"whats the weather in sf?\")]}\n",
        ")\n",
        "response[\"messages\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "GhxuLSulqIrp",
        "outputId": "37d19965-8c08-4fe1-c774-45a7daae4637"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'agent': {'messages': [AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_FbpJ8Lfs9xIPTZviTcQYOfgx', 'function': {'arguments': '{\\n  \"query\": \"current weather in San Francisco\"\\n}', 'name': 'tavily_search_results_json'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 23, 'prompt_tokens': 88, 'total_tokens': 111, 'completion_tokens_details': {'audio_tokens': None, 'reasoning_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': None, 'cached_tokens': 0}}, 'model_name': 'gpt-4-0613', 'system_fingerprint': None, 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-ddb8df56-f673-4b1a-889e-055b49f86704-0', tool_calls=[{'name': 'tavily_search_results_json', 'args': {'query': 'current weather in San Francisco'}, 'id': 'call_FbpJ8Lfs9xIPTZviTcQYOfgx', 'type': 'tool_call'}], usage_metadata={'input_tokens': 88, 'output_tokens': 23, 'total_tokens': 111, 'input_token_details': {'cache_read': 0}, 'output_token_details': {'reasoning': 0}})]}}\n",
            "----\n",
            "{'tools': {'messages': [ToolMessage(content='[{\"url\": \"https://www.weatherapi.com/\", \"content\": \"{\\'location\\': {\\'name\\': \\'San Francisco\\', \\'region\\': \\'California\\', \\'country\\': \\'United States of America\\', \\'lat\\': 37.775, \\'lon\\': -122.4183, \\'tz_id\\': \\'America/Los_Angeles\\', \\'localtime_epoch\\': 1728164819, \\'localtime\\': \\'2024-10-05 14:46\\'}, \\'current\\': {\\'last_updated_epoch\\': 1728164700, \\'last_updated\\': \\'2024-10-05 14:45\\', \\'temp_c\\': 27.8, \\'temp_f\\': 82.0, \\'is_day\\': 1, \\'condition\\': {\\'text\\': \\'Partly cloudy\\', \\'icon\\': \\'//cdn.weatherapi.com/weather/64x64/day/116.png\\', \\'code\\': 1003}, \\'wind_mph\\': 6.0, \\'wind_kph\\': 9.7, \\'wind_degree\\': 321, \\'wind_dir\\': \\'NW\\', \\'pressure_mb\\': 1014.0, \\'pressure_in\\': 29.95, \\'precip_mm\\': 0.0, \\'precip_in\\': 0.0, \\'humidity\\': 40, \\'cloud\\': 50, \\'feelslike_c\\': 27.5, \\'feelslike_f\\': 81.4, \\'windchill_c\\': 28.0, \\'windchill_f\\': 82.4, \\'heatindex_c\\': 27.9, \\'heatindex_f\\': 82.2, \\'dewpoint_c\\': 13.0, \\'dewpoint_f\\': 55.4, \\'vis_km\\': 16.0, \\'vis_miles\\': 9.0, \\'uv\\': 7.0, \\'gust_mph\\': 12.7, \\'gust_kph\\': 20.4}}\"}, {\"url\": \"https://forecast.weather.gov/MapClick.php?lat=37.777120000000025&lon=-122.41965999999996\", \"content\": \"Current conditions at SAN FRANCISCO DOWNTOWN (SFOC1) Lat: 37.77056Â°NLon: 122.42694Â°WElev: 150.0ft. NA. 58Â°F. 14Â°C. ... 2024-6pm PDT Oct 10, 2024 . Forecast Discussion . Additional Resources. Radar & Satellite Image. ... National Weather Service; San Francisco Bay Area, CA; 21 Grace Hopper Ave, Stop 5; Monterey, CA 93943-5505; Comments ...\"}]', name='tavily_search_results_json', id='9cf63789-62ba-453a-a3b9-4e78b2c14c25', tool_call_id='call_FbpJ8Lfs9xIPTZviTcQYOfgx', artifact={'query': 'current weather in San Francisco', 'follow_up_questions': None, 'answer': None, 'images': [], 'results': [{'title': 'Weather in San Francisco', 'url': 'https://www.weatherapi.com/', 'content': \"{'location': {'name': 'San Francisco', 'region': 'California', 'country': 'United States of America', 'lat': 37.775, 'lon': -122.4183, 'tz_id': 'America/Los_Angeles', 'localtime_epoch': 1728164819, 'localtime': '2024-10-05 14:46'}, 'current': {'last_updated_epoch': 1728164700, 'last_updated': '2024-10-05 14:45', 'temp_c': 27.8, 'temp_f': 82.0, 'is_day': 1, 'condition': {'text': 'Partly cloudy', 'icon': '//cdn.weatherapi.com/weather/64x64/day/116.png', 'code': 1003}, 'wind_mph': 6.0, 'wind_kph': 9.7, 'wind_degree': 321, 'wind_dir': 'NW', 'pressure_mb': 1014.0, 'pressure_in': 29.95, 'precip_mm': 0.0, 'precip_in': 0.0, 'humidity': 40, 'cloud': 50, 'feelslike_c': 27.5, 'feelslike_f': 81.4, 'windchill_c': 28.0, 'windchill_f': 82.4, 'heatindex_c': 27.9, 'heatindex_f': 82.2, 'dewpoint_c': 13.0, 'dewpoint_f': 55.4, 'vis_km': 16.0, 'vis_miles': 9.0, 'uv': 7.0, 'gust_mph': 12.7, 'gust_kph': 20.4}}\", 'score': 0.99841, 'raw_content': None}, {'title': 'National Weather Service', 'url': 'https://forecast.weather.gov/MapClick.php?lat=37.777120000000025&lon=-122.41965999999996', 'content': 'Current conditions at SAN FRANCISCO DOWNTOWN (SFOC1) Lat: 37.77056Â°NLon: 122.42694Â°WElev: 150.0ft. NA. 58Â°F. 14Â°C. ... 2024-6pm PDT Oct 10, 2024 . Forecast Discussion . Additional Resources. Radar & Satellite Image. ... National Weather Service; San Francisco Bay Area, CA; 21 Grace Hopper Ave, Stop 5; Monterey, CA 93943-5505; Comments ...', 'score': 0.99603915, 'raw_content': None}], 'response_time': 3.92})]}}\n",
            "----\n",
            "{'agent': {'messages': [AIMessage(content='The current weather in San Francisco, California is partly cloudy with a temperature of 27.8Â°C (82.0Â°F). The wind is coming from the northwest at 9.7 kph (6.0 mph). The humidity is at 40%. [Source](https://www.weatherapi.com/)', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 64, 'prompt_tokens': 684, 'total_tokens': 748, 'completion_tokens_details': {'audio_tokens': None, 'reasoning_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': None, 'cached_tokens': 0}}, 'model_name': 'gpt-4-0613', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-a0fed9bc-9f1b-42bc-b8ce-5194dd4922ed-0', usage_metadata={'input_tokens': 684, 'output_tokens': 64, 'total_tokens': 748, 'input_token_details': {'cache_read': 0}, 'output_token_details': {'reasoning': 0}})]}}\n",
            "----\n"
          ]
        }
      ],
      "source": [
        "for chunk in agent_executor.stream(\n",
        "    {\"messages\": [HumanMessage(content=\"whats the weather in sf?\")]}\n",
        "):\n",
        "    print(chunk)\n",
        "    print(\"----\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "0bURbsdLqQMd"
      },
      "outputs": [],
      "source": [
        "# Adding memory\n",
        "from langgraph.checkpoint.memory import MemorySaver\n",
        "\n",
        "memory = MemorySaver()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "bZaC13mbqtNf"
      },
      "outputs": [],
      "source": [
        "agent_executor = create_react_agent(model, tools, checkpointer=memory)\n",
        "\n",
        "# Just change thread_id to start new conversation\n",
        "config = {\"configurable\": {\"thread_id\": \"thread-1\"}}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "EmmP_OqGq17d",
        "outputId": "e154952a-0d41-4c0c-c3ab-89e58c4fe36f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'agent': {'messages': [AIMessage(content='Hello, Ramen! How can I assist you today?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 13, 'prompt_tokens': 110, 'total_tokens': 123, 'completion_tokens_details': {'audio_tokens': None, 'reasoning_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': None, 'cached_tokens': 0}}, 'model_name': 'gpt-4-0613', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-0291682f-404e-48c0-aca4-94c5b0a1b5b0-0', usage_metadata={'input_tokens': 110, 'output_tokens': 13, 'total_tokens': 123, 'input_token_details': {'cache_read': 0}, 'output_token_details': {'reasoning': 0}})]}}\n",
            "----\n"
          ]
        }
      ],
      "source": [
        "for chunk in agent_executor.stream(\n",
        "    {\"messages\": [HumanMessage(content=\"hello i'm ramen!\")]}, config\n",
        "):\n",
        "    print(chunk)\n",
        "    print(\"----\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "p1S0Sv4jq8Ku",
        "outputId": "aef72670-57e4-40e0-8389-c8bbc2d337f4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'agent': {'messages': [AIMessage(content='Your name is Ramen. How can I assist you further?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 14, 'prompt_tokens': 135, 'total_tokens': 149, 'completion_tokens_details': {'audio_tokens': None, 'reasoning_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': None, 'cached_tokens': 0}}, 'model_name': 'gpt-4-0613', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-69c835c9-ec9b-45b3-9e0b-006fbcdbe076-0', usage_metadata={'input_tokens': 135, 'output_tokens': 14, 'total_tokens': 149, 'input_token_details': {'cache_read': 0}, 'output_token_details': {'reasoning': 0}})]}}\n",
            "----\n"
          ]
        }
      ],
      "source": [
        "for chunk in agent_executor.stream(\n",
        "    {\"messages\": [HumanMessage(content=\"whats my name?\")]}, config\n",
        "):\n",
        "    print(chunk)\n",
        "    print(\"----\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        },
        "id": "cYuIgHMmrXI_",
        "outputId": "bddfcda3-f4df-4b52-c46d-599eeb07d453"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'A server is a computer or system that provides resources, data, services, or programs to other computers, known as clients, over a network. This structure is referred to as the clientâ€“server model. In essence, servers serve the information that clients request, hence the name. They play a crucial role in modern computing environments, powering everything from the internet to corporate networks to cloud services. \\n\\nThere are various types of servers, including web servers, mail servers, and file servers, each serving a specific purpose. For instance, a web server hosts websites and delivers web pages to users in response to their browser requests.\\n\\nYou can learn more about servers on [Wikipedia](https://en.wikipedia.org/wiki/Server_(computing)) or [Paessler](https://www.paessler.com/it-explained/server).'"
            ]
          },
          "execution_count": 35,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "response = agent_executor.invoke(\n",
        "    {\"messages\": [HumanMessage(content=\"Can you tell me more about servers?\")]}, config\n",
        ")\n",
        "response['messages'][-1].content\n",
        "\n",
        "# Assumes I was talking about computers."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 115,
      "metadata": {
        "id": "G9hajpNl55qf"
      },
      "outputs": [],
      "source": [
        "prompt = '''Ambiguity can arise when a word has multiple meanings. When a user's request is unclear or ambiguous, follow these steps:\n",
        "\n",
        "1. **Detect uncertainty**: If the request involves a word or phrase with multiple meanings (e.g., \"servers\" could refer to either computers or food servers), flag this ambiguity.\n",
        "\n",
        "2. **Ask a follow-up question**: If the user's request could be interpreted in multiple ways, ask a clarifying question to avoid assumptions. Use phrasing like:\n",
        "\n",
        "   - \"Are you asking about servers in the context of computers or food service?\"\n",
        "   - \"Could you clarify if you're referring to a server (computer) or a server (in a restaurant)?\"\n",
        "   - \"Do you mean servers as in IT infrastructure or servers as in people working at a restaurant?\"\n",
        "\n",
        "3. **Wait for clarification**: Do not proceed until the user confirms the intended meaning. Only after receiving a clear answer, proceed with the appropriate response.\n",
        "\n",
        "4. **Ensure a natural flow**: Maintain a conversational tone throughout, avoiding any abrupt shifts in behavior or phrasing. The goal is to make the interaction as human-like and helpful as possible.\n",
        "\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 116,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "UF5fe0ep6mmC",
        "outputId": "f5262b03-0a97-4480-b5e0-cb3ef5d2e20b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "I can definitely provide more information about servers. However, to give you the best answer, could you clarify if you're referring to a server in the context of computers and technology, or are you referring to servers as in people serving food in a restaurant?\n"
          ]
        }
      ],
      "source": [
        "agent_executor = create_react_agent(model, tools, state_modifier=prompt, checkpointer=memory)\n",
        "\n",
        "# Just change thread_id to start new conversation\n",
        "config = {\"configurable\": {\"thread_id\": \"thread-2\"}}\n",
        "\n",
        "response = agent_executor.invoke(\n",
        "    {\"messages\": [HumanMessage(content=\"Can you tell me more about servers?\")]}, config\n",
        ")\n",
        "print(response['messages'][-1].content)\n",
        "\n",
        "# Asks for clarifications before answering. Need to try if it still works when given a less specific prompt?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# First prompt to determine if clarification is needed\n",
        "prompt1 = '''\n",
        "Analyze the user's request and determine if it requires clarification due to ambiguity.\n",
        "If clarification is needed:\n",
        "1. Respond with \"CLARIFICATION_NEEDED: \" followed by the clarifying question.\n",
        "2. Example: \"CLARIFICATION_NEEDED: Are you asking about servers in the context of computers or food service?\"\n",
        "\n",
        "If no clarification is needed:\n",
        "1. Respond with \"NO_CLARIFICATION_NEEDED\"\n",
        "\n",
        "Always provide only one of these two responses, with no additional text.\n",
        "'''\n",
        "\n",
        "# Second prompt to handle the actual response\n",
        "prompt2 = '''\n",
        "You are an assistant that provides information based on the user's request.\n",
        "You will receive input in one of two formats:\n",
        "\n",
        "1. A user query followed by \"NO_CLARIFICATION_NEEDED\"\n",
        "   In this case, provide a detailed response to the user's query.\n",
        "\n",
        "2. A user query followed by \"CLARIFICATION_NEEDED: [question]\"\n",
        "   In this case, ask the clarifying question provided.\n",
        "\n",
        "Maintain a conversational tone and ensure your response is appropriate to the input received.\n",
        "'''\n",
        "\n",
        "agent_executor1 = create_react_agent(model, tools, state_modifier=prompt1, checkpointer=memory)\n",
        "agent_executor2 = create_react_agent(model, tools, state_modifier=prompt2, checkpointer=memory)\n",
        "\n",
        "# Usage remains the same as in your original code\n",
        "config = {\"configurable\": {\"thread_id\": \"thread-2\"}}\n",
        "response1 = agent_executor1.invoke(\n",
        "    {\"messages\": [HumanMessage(content=\"Can you tell me more about servers?\")]},\n",
        "    config\n",
        ")\n",
        "clarification_result = response1['messages'][-1].content\n",
        "\n",
        "response2 = agent_executor2.invoke(\n",
        "    {\"messages\": [HumanMessage(content=\"Can you tell me more about servers? \" + clarification_result)]},\n",
        "    config\n",
        ")\n",
        "print(response2['messages'][-1].content)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
